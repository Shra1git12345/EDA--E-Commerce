{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading & Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute+DataSet.csv\")\n",
    "inp1= pd.read_csv(\"Dress+Sales.csv\")\n",
    "inp0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have “Attribute DataSet” which contains a column named “Price”. Choose the correct statement from the following about its data type and variable type.\n",
    "- Integer type and numerical variable\n",
    "- Object type and categorical ordinal variable *\n",
    "- Object type and categorical nominal variable\n",
    "- Float type and categorical variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another column in “Attribute DataSet” named as “Recommendation”, choose the correct statement about its data type and variable type.\n",
    "- Integer type and categorical *\n",
    "- Object type and categorical\n",
    "- Integer type and continuous numerical\n",
    "- Object type only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following column do you think are of no use in “Attribute DataSet”.\n",
    "- Dress_ID\n",
    "- Price\n",
    "- Size and material\n",
    "- NeckLine\n",
    "- None of the above *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  479 non-null    object \n",
      " 9   14-09-2013  479 non-null    object \n",
      " 10  16-09-2013  479 non-null    object \n",
      " 11  18-09-2013  479 non-null    object \n",
      " 12  20-09-2013  479 non-null    object \n",
      " 13  22-09-2013  479 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information about the attributes of inp0 and inp1.\n",
    "inp0.info()\n",
    "inp1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Rows and Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a column in “Attribute Dataset” named as ‘Size’. This column contains the values in abbreviation format. Write a code in Python to convert the followings:\n",
    "\n",
    "- M into  “Medium”\n",
    "- L into  “Large”\n",
    "- XL into “Extra large”\n",
    "- free into “Free”\n",
    "- S, s & small into “Small”.\n",
    "\n",
    "Now once you are done with changes in the dataset, what is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named “Size”?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column fixing, correcting size abbreviation. count the percentage of each size category in \"Size\" column.\n",
    "inp0.Size= inp0.Size.replace(['S', 'small', 's'], \"Small\")\n",
    "\n",
    "inp0.Size= inp0.Size.replace('free', \"Free\")\n",
    "\n",
    "inp0.Size= inp0.Size.replace('M', \"Medium\")\n",
    "\n",
    "inp0.Size= inp0.Size.replace('L', \"Large\") \n",
    "\n",
    "inp0.Size= inp0.Size.replace('XL', \"Extra large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Size\n",
       "Medium         0.356994\n",
       "Free           0.344468\n",
       "Large          0.194154\n",
       "Small          0.075157\n",
       "Extra large    0.029228\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the value counts of each category in \"Size\" column.\n",
    "inp0.Size.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute/Remove Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
       "0    1.006033e+09        2114        2274        2491        2660        2727   \n",
       "1    1.212192e+09         151         275         570         750         813   \n",
       "2    1.190381e+09           6           7           7           7           8   \n",
       "3    9.660060e+08        1005        1128        1326        1455        1507   \n",
       "4    8.763395e+08         996        1175        1304        1396        1432   \n",
       "..            ...         ...         ...         ...         ...         ...   \n",
       "474  9.905592e+08           0           0           0          60          62   \n",
       "475  7.133920e+08           0           0           0         560         554   \n",
       "476  5.328743e+08           0           0           0         734         728   \n",
       "477  6.554649e+08           0           0           0         254         259   \n",
       "478  9.199310e+08           0           0           0         538         545   \n",
       "\n",
       "     09-08-2013  09-10-2013 09-12-2013 14-09-2013  ... 24-09-2013 26-09-2013  \\\n",
       "0          2887        2930       3119       3204  ...       3554     3624.0   \n",
       "1          1066        1164       1558       1756  ...       2710     2942.0   \n",
       "2             8           9         10         10  ...         11       11.0   \n",
       "3          1621        1637       1723       1746  ...       1878     1892.0   \n",
       "4          1559        1570       1638       1655  ...       2032     2156.0   \n",
       "..          ...         ...        ...        ...  ...        ...        ...   \n",
       "474          64          65         67         68  ...         73       74.0   \n",
       "475         544         537        525        519  ...        400      388.0   \n",
       "476         726         715        694        690  ...        616      597.0   \n",
       "477         261         263        268        270  ...        257      256.0   \n",
       "478         558         563        578        585  ...        628      632.0   \n",
       "\n",
       "    28-09-2013 30-09-2013  10-02-2013  10-04-2013  10-06-2013  10-08-2013  \\\n",
       "0         3706     3746.0      3795.0      3832.0        3897      3923.0   \n",
       "1         3258     3354.0      3475.0      3654.0        3911      4024.0   \n",
       "2           11       11.0        11.0        11.0          11        11.0   \n",
       "3         1914     1924.0      1929.0      1941.0        1952      1955.0   \n",
       "4         2252     2312.0      2387.0      2459.0        2544      2614.0   \n",
       "..         ...        ...         ...         ...         ...         ...   \n",
       "474         75       75.0        76.0        76.0          77        77.0   \n",
       "475        360      364.0       372.0       377.0         380       382.0   \n",
       "476        586      569.0       561.0       555.0         551       546.0   \n",
       "477        255      254.0       253.0       250.0         249       249.0   \n",
       "478        639      645.0       651.0       655.0         660       668.0   \n",
       "\n",
       "     10-10-2013  10-12-2013  \n",
       "0        3985.0        4048  \n",
       "1        4125.0        4277  \n",
       "2          11.0          11  \n",
       "3        1959.0        1963  \n",
       "4        2693.0        2736  \n",
       "..          ...         ...  \n",
       "474        77.0          77  \n",
       "475       384.0         285  \n",
       "476       535.0         520  \n",
       "477       249.0         248  \n",
       "478       674.0         680  \n",
       "\n",
       "[479 rows x 24 columns]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp1.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given another dataset named “Dress Sales”. Now if you observe the datatypes of the columns using ‘inp1.info()’ command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n",
    "\n",
    "Now if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Try to correct this error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "inp1.loc[inp1['09-12-2013']== 'removed',\"09-12-2013\"] = np.NaN\n",
    "\n",
    "inp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\n",
    "\n",
    "inp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\n",
    "\n",
    "inp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\n",
    "\n",
    "inp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\n",
    "\n",
    "inp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the object type columns in \"Dress Sales\" into float type of data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see the null counts in “Dress Sales” dataset after performing all the operations that have been mentioned in jupyter notebook, you will find that there are some columns in “Dress Sales” data where there are more than 40% of missing values. Based on your understanding of dealing with missing values do the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the null percentange of each column of inp1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['26-09-2013'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m inp1\u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m26-09-2013\u001b[39m\u001b[38;5;124m\"\u001b[39m] , axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m inp1\u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m30-09-2013\u001b[39m\u001b[38;5;124m\"\u001b[39m] , axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m inp1\u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10-02-2013\u001b[39m\u001b[38;5;124m\"\u001b[39m] , axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['26-09-2013'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "inp1= inp1.drop([\"26-09-2013\"] , axis= 1)\n",
    "\n",
    "inp1= inp1.drop([\"30-09-2013\"] , axis= 1)\n",
    "\n",
    "inp1= inp1.drop([\"10-02-2013\"] , axis= 1)\n",
    "\n",
    "inp1= inp1.drop([\"10-04-2013\"] , axis= 1)\n",
    "\n",
    "inp1= inp1.drop([\"10-08-2013\"] , axis= 1)\n",
    "\n",
    "inp1= inp1.drop([\"10-10-2013\"] , axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should categorise the dates into seasons in “Dress Sales” data to simplify the analysis according to the following criteria:\n",
    "- June, July and August: Summer.\n",
    "- September, October and November: Autumn.\n",
    "- December, January and February: WInter.\n",
    "- March, April and May: Spring.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the four seasons columns in inp1, according to the above criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpring\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-04-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m31-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-06-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-06-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-02-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-12-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-12-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutumn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-10-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m14-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m22-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m24-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m28-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpring\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-04-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m31-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-06-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-06-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-02-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-12-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-12-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutumn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m09-10-2013\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m14-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m22-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m24-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m28-09-2013\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# calculate the sum of sales in each seasons in inp1 i.e. \"Dress Sales\".\n",
    "inp1['Spring'] = inp1.apply(lambda x: x['09-04-2013'], axis=1)\n",
    "\n",
    "inp1['Summer'] = inp1.apply(lambda x: x['29-08-2013'] + x['31-08-2013']+ x['09-06-2013']+ x['09-08-2013']+ x['10-06-2013'], axis=1)\n",
    "\n",
    "inp1['Winter'] = inp1.apply(lambda x: x['09-02-2013'] + x['09-12-2013']+ x['10-12-2013'], axis=1)\n",
    "\n",
    "inp1['Autumn'] = inp1.apply(lambda x: x['09-10-2013'] + x['14-09-2013']+ x['16-09-2013']+ x['18-09-2013']+ x['20-09-2013']+ x['22-09-2013']+ x['24-09-2013']+ x['28-09-2013'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge inp1 with inp0 with left join manner, so that the information of inp0 should remain intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>...</th>\n",
       "      <th>16-09-2013_y</th>\n",
       "      <th>18-09-2013_y</th>\n",
       "      <th>20-09-2013_y</th>\n",
       "      <th>22-09-2013_y</th>\n",
       "      <th>24-09-2013_y</th>\n",
       "      <th>28-09-2013_y</th>\n",
       "      <th>10-06-2013_y</th>\n",
       "      <th>10-12-2013_y</th>\n",
       "      <th>Spring_y</th>\n",
       "      <th>Summer_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>3277</td>\n",
       "      <td>3321</td>\n",
       "      <td>3386</td>\n",
       "      <td>3479</td>\n",
       "      <td>3554</td>\n",
       "      <td>3706</td>\n",
       "      <td>3897</td>\n",
       "      <td>4048</td>\n",
       "      <td>2660</td>\n",
       "      <td>13899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1878</td>\n",
       "      <td>1985</td>\n",
       "      <td>2106</td>\n",
       "      <td>2454</td>\n",
       "      <td>2710</td>\n",
       "      <td>3258</td>\n",
       "      <td>3911</td>\n",
       "      <td>4277</td>\n",
       "      <td>750</td>\n",
       "      <td>6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Large</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1783</td>\n",
       "      <td>1796</td>\n",
       "      <td>1812</td>\n",
       "      <td>1845</td>\n",
       "      <td>1878</td>\n",
       "      <td>1914</td>\n",
       "      <td>1952</td>\n",
       "      <td>1963</td>\n",
       "      <td>1455</td>\n",
       "      <td>7213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1681</td>\n",
       "      <td>1743</td>\n",
       "      <td>1824</td>\n",
       "      <td>1919</td>\n",
       "      <td>2032</td>\n",
       "      <td>2252</td>\n",
       "      <td>2544</td>\n",
       "      <td>2736</td>\n",
       "      <td>1396</td>\n",
       "      <td>7706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating    Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6  Medium  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0   Large  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0   Large  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6   Large  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5  Medium  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  ... 16-09-2013_y 18-09-2013_y  20-09-2013_y  \\\n",
       "0            NaN    chiffon  ...         3277         3321          3386   \n",
       "1     microfiber        NaN  ...         1878         1985          2106   \n",
       "2       polyster        NaN  ...           10           10            10   \n",
       "3           silk    chiffon  ...         1783         1796          1812   \n",
       "4  chiffonfabric    chiffon  ...         1681         1743          1824   \n",
       "\n",
       "   22-09-2013_y  24-09-2013_y  28-09-2013_y  10-06-2013_y  10-12-2013_y  \\\n",
       "0          3479          3554          3706          3897          4048   \n",
       "1          2454          2710          3258          3911          4277   \n",
       "2            11            11            11            11            11   \n",
       "3          1845          1878          1914          1952          1963   \n",
       "4          1919          2032          2252          2544          2736   \n",
       "\n",
       "   Spring_y  Summer_y  \n",
       "0      2660     13899  \n",
       "1       750      6216  \n",
       "2         7        40  \n",
       "3      1455      7213  \n",
       "4      1396      7706  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "inp0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'29-08-2013'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '29-08-2013'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now Drop the Date columns from inp0 as it is already combined into four seasons.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m inp0\u001b[38;5;241m.\u001b[39mdrop(inp0\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29-08-2013\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-12-2013\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns, axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m inp0\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1289\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(retval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1323\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1355\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1354\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1355\u001b[0m indexer \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mslice_indexer(slice_obj\u001b[38;5;241m.\u001b[39mstart, slice_obj\u001b[38;5;241m.\u001b[39mstop, slice_obj\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6344\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[0;32m   6301\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   6302\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6303\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6304\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6305\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[0;32m   6306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6307\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6342\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6344\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_locs(start, end, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m   6346\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6537\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6535\u001b[0m start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6537\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slice_bound(start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6539\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6462\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_searchsorted_monotonic(label, side)\n\u001b[0;32m   6460\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   6461\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m-> 6462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   6464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   6465\u001b[0m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[0;32m   6466\u001b[0m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[0;32m   6467\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6456\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6454\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6456\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   6457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   6458\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '29-08-2013'"
     ]
    }
   ],
   "source": [
    "# Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "inp0.drop(inp0.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the null count of inp0 to get the idea about the missing values in data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the null count of each columns in inp0 dataframe i.e. combined data frame of inp0 and inp1 without date columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are two types of variables one with a large number of missing values and another is very less number of missing values. These two columns can be categorized as:\n",
    "\n",
    "Type-1: Missing values are very less (around 2 or 3 missing values): Price, Season, NeckLine, SleeveLength, Winter and Autumn. \n",
    "\n",
    "Type-2: Missing values are large in numbers (more than 15%): Material, FabricType, Decoration and Pattern Type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Winter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8996\\8832245.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeckLine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0minp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSleeveLength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0minp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0minp0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Winter'"
     ]
    }
   ],
   "source": [
    "# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "inp0 = inp0[~inp0.Price.isnull()]\n",
    "\n",
    "inp0 = inp0[~inp0.Season.isnull()]\n",
    "\n",
    "inp0 = inp0[~inp0.NeckLine.isnull()]\n",
    "\n",
    "inp0 = inp0[~inp0.SleeveLength.isnull()]\n",
    "\n",
    "inp0 = inp0[~inp0.Winter.isnull()]\n",
    "\n",
    "inp0 = inp0[~inp0.Autumn.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\n",
    "inp0.Material= inp0.Material.replace(np.nan, \"Missing\")\n",
    "\n",
    "inp0.FabricType= inp0.FabricType.replace(np.nan, \"Missing\")\n",
    "\n",
    "inp0.Decoration= inp0.Decoration.replace(np.nan, \"Missing\")\n",
    "\n",
    "inp0['Pattern Type']= inp0['Pattern Type'].replace(np.nan, \"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given dataset, there are certain discrepancies with the categorical names such as irregular spellings. Choose the correct option of columns with irregular categories and update them.\n",
    " \n",
    "- Season, NeckLine\n",
    "- Price, Material\n",
    "- fabricType, Decoration\n",
    "- Season, SleeveLength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the spellings.\n",
    "inp0.Season= inp0.Season.replace('Automn', \"Autumn\")\n",
    "\n",
    "inp0.Season= inp0.Season.replace('spring', \"Spring\")\n",
    "\n",
    "inp0.Season= inp0.Season.replace('winter', \"Winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the Sleevelength.\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace(['cap-sleeves', 'capsleeves'], \"cap sleeves\")\n",
    "\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace('full', \"full sleeves\")\n",
    "\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace(['half','halfsleeve'], \"half sleeves\")\n",
    "\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace(['sleevless', 'sleeevless', 'sleeveless', 'sleveless'], \"sleeve less\")\n",
    "\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace(['threequarter','threequater', 'thressqatar'], \"three quater\")\n",
    "\n",
    "inp0.SleeveLength= inp0.SleeveLength.replace(['turndowncollor','urndowncollor'], \"turn down collar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Unordered Univariate Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named ‘Style’ in ‘Attribute Dataset’ which consists of the different style categories of the women apparels. Certain categories whose total sale is less than 50000 across all the seasons is considered under one single category as ‘Others’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following categories in ‘Style’ column can be grouped into ‘Others’ category? and perform the grouping operation in the notebook for further analysis.\n",
    "- Flare, fashion\n",
    "- Novelty, bohemian\n",
    "- OL, fashion, work\n",
    "- Novelty, fashion, Flare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Style\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['Style'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of “cute” and “Others” category in “Style” column in “Attribute DataSet” respectively?\n",
    "- 46%, 5%\n",
    "- 9%, 2.1%\n",
    "- 2.1%, 5%\n",
    "- 13.8%, 9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each categories in the \"Style\" variable.\n",
    "print(inp0.Style.value_counts(normalize=True))\n",
    "inp0.Style.value_counts(normalize=True).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly Club Neckline, SLeeve length categories into \"Others\" which have less than 50000 sales across all the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['Neckline'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Sleeve length\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['Sleeve length'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club material, fabrictype, patterntype and decoration categories into \"Others\" which have less than 25000 sales across all the seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"material\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['material'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"fabric type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['fabric type'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"patern type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['patern type'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"decoration\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "total_collection=inp0.groupby(['decoration'])['Spring','Winter','Autumn', 'Summer'].sum()\n",
    "\n",
    "total_collection.sum(axis = 1)\n",
    "#Find the categories that have sales values less than 50,000 across all the seasons.\n",
    "\n",
    "total_collection[total_collection.sum(axis= 1)<50000]\n",
    "#Group the Style categories that have sales less than 50,000 across all the seasons under ‘Others’.\n",
    "\n",
    "inp0.replace(total_collection[total_collection.sum(axis=1)<50000].index, 'Others', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caregorical Ordered Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an unordered variable in “Attribute DataSet”.\n",
    "- Style*\n",
    "- Price\n",
    "- Season\n",
    "- Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable Univariate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the approximate difference between the maximum value and 75th percentile in “Autumn” column.\n",
    "- Approx 54000\n",
    "- Approx 55000\n",
    "- Approx 52000 *\n",
    "- Approx 50000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the numerical variale: \"Autumn\".\n",
    "inp0.Autumn.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot of \"Autumn\" column.\n",
    "sns.boxplot(inp0.Autumn)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest difference between the maximum value and 99th quantile of sales?\n",
    "- Winter\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Winter season.\n",
    "inp0.Winter.quantile([0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Summer season.\n",
    "inp0.Autumn.quantile([0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Spring season.\n",
    "inp0.Spring.quantile([0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Autumn season.\n",
    "inp0.Autumn.quantile([0.99, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical- Categorical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following “Price” category has the lowest average value of rating?\n",
    "- very-high\n",
    "- Medium\n",
    "- Low\n",
    "- High*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Mean of Ratings for each Price category.\n",
    "print(inp0.groupby('Price')['Rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median of the rating of “vintage” category in Style column?\n",
    "- 4.6*\n",
    "- 4.7\n",
    "- 4.55\n",
    "- 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the median of Ratings for each Style category.\n",
    "print(inp0.groupby('Style')['Rating'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest average value of sale for “Recommendation” value equals to 1.\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn*\n",
    "- Winter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer sale vs Recommendation.\n",
    "print(inp0.groupby('Recommendation')['Summer'].mean())\n",
    "\n",
    "sns.boxplot(data=inp0, x=\"Recommendation\",y=\"Autumn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spring sale vs Recommendation.\n",
    "print(inp0.groupby('Recommendation')['Spring'].mean())\n",
    "\n",
    "sns.boxplot(data=inp0, x=\"Recommendation\",y=\"Autumn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autumn sale vs Recommendation.\n",
    "print(inp0.groupby('Recommendation')['Autumn'].mean())\n",
    "\n",
    "sns.boxplot(data=inp0, x=\"Recommendation\",y=\"Autumn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winter sale vs Recommendation.\n",
    "print(inp0.groupby('Recommendation')['Winter'].mean())\n",
    "\n",
    "sns.boxplot(data=inp0, x=\"Recommendation\",y=\"Autumn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical categorical bivariate analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following size categories has the highest positive recommendations?\n",
    "- Medium and extra large\n",
    "- Extra large and small\n",
    "- Free and small\n",
    "- Free and medium*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size vs Recommendation.\n",
    "inp0.groupby(['Size'])['Recommendation'].mean().plot.barh()\n",
    "inp0.groupby('Size')['Recommendation'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following pair of “Style” and “Price” category has the highest average of positive recommendations?\n",
    "- Price: medium and style: vintage\n",
    "- Price: medium and style: cute*\n",
    "- Price: very high and style: party\n",
    "- Price: low and style: sexy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Style, price and Recommendation.\n",
    "res = pd.pivot_table(data=inp0, index=\"Style\", columns=\"Price\", values=\"Recommendation\")\n",
    "\n",
    "sns.heatmap(res, cmap=\"RdYlGn\", annot=True, center=0.427)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following material type has no recommendation in summer and winter seasons?\n",
    "- Mix and Milksilk\n",
    "- Nylon and Rayon\n",
    "- Microfiber and Silk\n",
    "- Milksilk and Microfiber*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Season, material and Recommendation.\n",
    "res = pd.pivot_table(data=inp0, index=\"Material\", columns=\"Season\", values=\"Recommendation\")\n",
    "\n",
    "sns.heatmap(res, cmap=\"RdYlGn\", annot=True, center=0.427)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
